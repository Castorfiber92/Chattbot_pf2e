{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "833d36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import fitz\n",
    "import time\n",
    "import polars as pl\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d003fb",
   "metadata": {},
   "source": [
    "### Pre-processing and general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "375e1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function for transforming the pdf's to a readable state. \n",
    "def remove_headers_and_footers(\n",
    "    pdf_path, header_height_pt=70, footer_height_pt=70\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF, excluding the header and footer areas.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        header_height_pt (int, optional): Height of the header area in points.\n",
    "            Defaults to 50 (a reasonable starting value).\n",
    "        footer_height_pt (int, optional): Height of the footer area in points.\n",
    "            Defaults to 50 (a reasonable starting value).\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text without the header and footer.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        page_rect = page.rect  # Get the page rectangle\n",
    "        page_height = page_rect.height\n",
    "        # Define the clipping rectangle, excluding header and footer\n",
    "        clip_rect = fitz.Rect(\n",
    "            page_rect.x0,\n",
    "            header_height_pt,\n",
    "            page_rect.x1,\n",
    "            page_height - footer_height_pt,\n",
    "        )\n",
    "        text += page.get_text(clip=clip_rect) + \"\\n\"  # Add newline between pages\n",
    "    doc.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1f42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09d48075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to create a embedding for an input.\n",
    "def get_embedding(text, model=\"text-embedding-004\", delay = 0.6):\n",
    "    \"\"\"\n",
    "    Creates an embedding for the given text using Genai.\n",
    "\n",
    "    Args:\n",
    "    text (str): Input text.\n",
    "    model (str): Embedding model name.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The embedding vector.\n",
    "    \"\"\"\n",
    "    time.sleep(delay)\n",
    "    response = client.models.embed_content(\n",
    "              model=model, \n",
    "              contents=text)\n",
    "    \n",
    "    return response.embeddings[0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dc9971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text_chunks):\n",
    "    \"\"\"\n",
    "    Creates embeddings for each text chunk.\n",
    "\n",
    "    Args:\n",
    "    text_chunks (List[str]): List of text chunks.\n",
    "\n",
    "    Returns:\n",
    "    List[np.ndarray]: List of embedding vectors.\n",
    "    \"\"\"\n",
    "    # Generate embeddings for each text chunk using the get_embedding function\n",
    "    return [get_embedding(chunk) for chunk in text_chunks]\n",
    "\n",
    "# Create chunk embeddings using the create_embeddings function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bfaa1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function for calculating the cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Computes cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "    vec1 (np.ndarray): First vector.\n",
    "    vec2 (np.ndarray): Second vector.\n",
    "\n",
    "    Returns:\n",
    "    float: Cosine similarity.\n",
    "    \"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bde0b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_breakpoints(similarities, method=\"percentile\", threshold=90):\n",
    "    \"\"\"\n",
    "    Computes chunking breakpoints based on similarity drops.\n",
    "\n",
    "    Args:\n",
    "    similarities (List[float]): List of similarity scores between sentences.\n",
    "    method (str): 'percentile', 'standard_deviation', or 'interquartile'.\n",
    "    threshold (float): Threshold value (percentile for 'percentile', std devs for 'standard_deviation').\n",
    "\n",
    "    Returns:\n",
    "    List[int]: Indices where chunk splits should occur.\n",
    "    \"\"\"\n",
    "    # Determine the threshold value based on the selected method\n",
    "    if method == \"percentile\":\n",
    "        # Calculate the Xth percentile of the similarity scores\n",
    "        threshold_value = np.percentile(similarities, threshold)\n",
    "    elif method == \"standard_deviation\":\n",
    "        # Calculate the mean and standard deviation of the similarity scores\n",
    "        mean = np.mean(similarities)\n",
    "        std_dev = np.std(similarities)\n",
    "        # Set the threshold value to mean minus X standard deviations\n",
    "        threshold_value = mean - (threshold * std_dev)\n",
    "    elif method == \"interquartile\":\n",
    "        # Calculate the first and third quartiles (Q1 and Q3)\n",
    "        q1, q3 = np.percentile(similarities, [25, 75])\n",
    "        # Set the threshold value using the IQR rule for outliers\n",
    "        threshold_value = q1 - 1.5 * (q3 - q1)\n",
    "    else:\n",
    "        # Raise an error if an invalid method is provided\n",
    "        raise ValueError(\"Invalid method. Choose 'percentile', 'standard_deviation', or 'interquartile'.\")\n",
    "\n",
    "    # Identify indices where similarity drops below the threshold value\n",
    "    return [i for i, sim in enumerate(similarities) if sim < threshold_value]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53875aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(sentences, breakpoints):\n",
    "    \"\"\"\n",
    "    Splits sentences into semantic chunks.\n",
    "\n",
    "    Args:\n",
    "    sentences (List[str]): List of sentences.\n",
    "    breakpoints (List[int]): Indices where chunking should occur.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: List of text chunks.\n",
    "    \"\"\"\n",
    "    chunks = []  # Initialize an empty list to store the chunks\n",
    "    start = 0  # Initialize the start index\n",
    "\n",
    "    # Iterate through each breakpoint to create chunks\n",
    "    for bp in breakpoints:\n",
    "        # Append the chunk of sentences from start to the current breakpoint\n",
    "        chunks.append(\". \".join(sentences[start:bp + 1]) + \".\")\n",
    "        start = bp + 1  # Update the start index to the next sentence after the breakpoint\n",
    "\n",
    "    # Append the remaining sentences as the last chunk\n",
    "    chunks.append(\". \".join(sentences[start:]))\n",
    "    return chunks  # Return the list of chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6589c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, text_chunks, chunk_embeddings, k=5):\n",
    "    \"\"\"\n",
    "    Finds the most relevant text chunks for a query.\n",
    "\n",
    "    Args:\n",
    "    query (str): Search query.\n",
    "    text_chunks (List[str]): List of text chunks.\n",
    "    chunk_embeddings (List[np.ndarray]): List of chunk embeddings.\n",
    "    k (int): Number of top results to return.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: Top-k relevant chunks.\n",
    "    \"\"\"\n",
    "    # Generate an embedding for the query\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    # Calculate cosine similarity between the query embedding and each chunk embedding\n",
    "    similarities = [cosine_similarity(query_embedding, emb) for emb in chunk_embeddings]\n",
    "    \n",
    "    # Get the indices of the top-k most similar chunks\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    \n",
    "    # Return the top-k most relevant text chunks\n",
    "    return [text_chunks[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d200f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt(query):\n",
    "    context = \"\\n\".join(semantic_search(query, vector_store_fixed_length.texts, vector_store_fixed_length.vectors))\n",
    "    user_prompt = f\"The question is {query}. This is the context: {context}.\"\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49d2b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt(query, texts, embeddings):\n",
    "    context = \"\\n\".join(semantic_search(query, texts, embeddings))\n",
    "    user_prompt = f\"The question is {query}. This is the context: {context}.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c27ac74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the generate respone function.\n",
    "def generate_response(system_prompt, user_message, texts, embeddings, model=\"gemini-2.0-flash\", ):\n",
    "    \"\"\"\n",
    "    Generates a response from the AI model based on the system prompt and user message.\n",
    "\n",
    "    Args:\n",
    "    system_prompt (str): The system prompt to guide the AI's behavior.\n",
    "    user_message (str): The user's message or query.\n",
    "    model (str): The model to be used for generating the response. Default is \"meta-llama/Llama-2-7B-chat-hf\".\n",
    "\n",
    "    Returns:\n",
    "    dict: The response from the AI model.\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt),\n",
    "        contents=generate_user_prompt(user_message, texts, embeddings)\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553cd75",
   "metadata": {},
   "source": [
    "### Converting pdfs and merging to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e87abbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the path to the PDF file and merging all the pdfs\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "pdf_folder = os.path.join(notebook_dir, 'materials')\n",
    "\n",
    "pdf_file_path_1 = os.path.join(pdf_folder, 'Summer_that_never_was.pdf')\n",
    "pdf_file_path_2 = os.path.join(pdf_folder, 'Let_the_leaves_fall.pdf')\n",
    "pdf_file_path_3 = os.path.join(pdf_folder, 'No_breath_to_cry.pdf')\n",
    "pdf_file_path_4 = os.path.join(pdf_folder, 'To_bloom_below_the_web.pdf')\n",
    "\n",
    "text_1 = remove_headers_and_footers(pdf_file_path_1)\n",
    "text_2 = remove_headers_and_footers(pdf_file_path_2)\n",
    "text_3 = remove_headers_and_footers(pdf_file_path_3)\n",
    "text_4 = remove_headers_and_footers(pdf_file_path_4)\n",
    "\n",
    "extracted_text = text_1 + text_2 + text_3 + text_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting text into sentences (basic split)\n",
    "sentences = extracted_text.split(\". \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e5edd0",
   "metadata": {},
   "source": [
    "### Making the embeddings for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fbdf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for each sentence\n",
    "embeddings = [get_embedding(sentence) for sentence in sentences]\n",
    "print(f\"Generated {len(embeddings)} sentence embeddings.\")\n",
    "print(f\"From {len(sentences)} sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute breakpoints using the percentile method with a threshold of 90\n",
    "# Compute similarity between consecutive sentences\n",
    "similarities = [cosine_similarity(embeddings[i], embeddings[i + 1]) for i in range(len(embeddings) - 1)]\n",
    "\n",
    "breakpoints = compute_breakpoints(similarities, method=\"percentile\", threshold=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunks using the split_into_chunks function\n",
    "text_chunks = split_into_chunks(sentences, breakpoints)\n",
    "\n",
    "chunk_embeddings = create_embeddings(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d07e626",
   "metadata": {},
   "source": [
    "### Making the embeddings for Fixed length chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "n = 2000\n",
    "overlap = 400\n",
    "\n",
    "for i in range (0, len(extracted_text), n -overlap): \n",
    "    chunks.append(extracted_text[i:i+n])\n",
    "\n",
    "print(f\"Antal chunks: {len(chunks)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length_embeddings = create_embeddings(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb45e2",
   "metadata": {},
   "source": [
    "### Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cd17e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self):\n",
    "        self.vectors = []\n",
    "        self.texts = []\n",
    "        self.metadata = []\n",
    "    #tagit bort np.array framfÃ¶r embedding i append\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        self.vectors.append(np.array(embedding))\n",
    "        self.texts.append(text)\n",
    "        self.metadata.append(metadata or {})\n",
    "\n",
    "    def semantic_search(self, query_embedding, k=5):\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "        query_vector = np.array(query_embedding)\n",
    "\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity))\n",
    "        \n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\"text\": self.texts[idx],\n",
    "                            \"metadata\": self.metadata[idx],\n",
    "                            \"similarity\": score\n",
    "                            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save(self, filename):\n",
    "        df = pl.DataFrame(\n",
    "            dict(\n",
    "                vectors=self.vectors,\n",
    "                texts=self.texts,\n",
    "                metadata=self.metadata))\n",
    "        df.write_parquet(filename)\n",
    "\n",
    "    def load(self, file):\n",
    "        df = pl.read_parquet(file, columns=[\"vectors\", \"texts\", \"metadata\"])\n",
    "        self.vectors = df[\"vectors\"].to_list()\n",
    "        self.texts = df[\"texts\"].to_list()\n",
    "        self.metadata = df[\"metadata\"].to_list()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802cc776",
   "metadata": {},
   "source": [
    "#### Saving the semantic seartch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa117199",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_s_search = VectorStore()\n",
    "for i, chunk in enumerate(text_chunks):\n",
    "    vector_store_s_search.add_item(text=text_chunks[i], embedding=chunk_embeddings[i], metadata={\"type\": \"chunk\", \"index\": i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_s_search.save(\"embeddings_s_search.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c175281b",
   "metadata": {},
   "source": [
    "#### Saving the fixed length model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ac5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_fixed_length = VectorStore()\n",
    "for i, chunk in enumerate(chunks):\n",
    "    vector_store_fixed_length.add_item(text=chunks[i], embedding=fixed_length_embeddings[i], metadata={\"type\": \"chunk\", \"index\": i})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188642e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_fixed_length.save(\"embeddings_fixed_length.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273e2dc",
   "metadata": {},
   "source": [
    "#### Loading both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e7fabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_s_search = VectorStore()\n",
    "vector_store_s_search.load(\"embeddings_s_search.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc3e2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_fixed_length = VectorStore()\n",
    "vector_store_fixed_length.load(\"embeddings_fixed_length.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b57311",
   "metadata": {},
   "source": [
    "### Using the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ace21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the system prompt for the AI assistant\n",
    "system_prompt = \"You are an AI assistant that gives guidence based on the given context. The context is an adventure for a TTRPG called 'Pathfinder 2e'. Give fleshed out answers point by point, but make sure to indicate what part's you are less certain about.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a breakdown of the first day walking the Pilgrim's Path, focusing on potential dangers and things to consider:\n",
      "\n",
      "**The First Day on the Pilgrim's Path:**\n",
      "\n",
      "*   **Setting the Scene:** The first day should emphasize the sense of leaving the familiar behind. The party departs the Mountain Shrine and enters the Pilgrim's Path. Describe the immediate change in the environment (if any). Is the path well-worn or overgrown? Are there immediate visual cues indicating they are now on a special, perhaps sacred, route?\n",
      "\n",
      "*   **Initial Pace and Ritual:** Remind the players that they cannot rush this journey. Describe the pace as deliberate and meditative. They need to adhere to any known Pilgrim's Path traditions (which you should have conveyed beforehand). Are there prayers to be said? Specific ways they should step or orient themselves on the path? A specific order to walk in? Failure to adhere to these traditions might have consequences (see \"Dangers\" below).\n",
      "\n",
      "*   **Environmental Description:** Provide sensory details of the path itself. What is the weather like? Is the path dusty, muddy, rocky, or smooth? What does the surrounding foliage look like? Are there sounds of wildlife, or an unnatural silence?\n",
      "\n",
      "**Potential Dangers on Day One:**\n",
      "\n",
      "*   **Breaking Tradition:** This is perhaps the most insidious danger. If the players are not diligent in following the Pilgrim's Path traditions, something negative could occur. This could be subtle at first:\n",
      "\n",
      "    *   **Minor Inconveniences:** Increased fatigue, equipment malfunctions (a waterskin springs a leak, a boot comes apart), unsettling dreams.\n",
      "    *   **Magical Penalties:** A feeling of unease, temporary penalties to wisdom or charisma checks, or a warding glyph appearing on their equipment that causes disadvantage on certain actions.\n",
      "    *   **Attracting Unwanted Attention:** Straying from the traditions could attract the attention of negative entities drawn to those who disrespect the path.\n",
      "\n",
      "*   **Environmental Hazards:** Even without supernatural elements, the wilderness is dangerous.\n",
      "\n",
      "    *   **Weather:** A sudden downpour could make the path treacherous. Heat exhaustion or hypothermia are possibilities depending on the climate.\n",
      "    *   **Terrain:** A misstep on a rocky section of the path could lead to an injury (sprained ankle, twisted knee).\n",
      "    *   **Natural Predators:** While the Pilgrim's Path is generally safe, it's still a wild area. Wolves, boars, or other predators might be present, especially if the party is noisy or careless.\n",
      "    *   **Poisonous Plants/Insects:** depending on the location, be on the lookout for poisonous plants and stinging insects.\n",
      "\n",
      "*   **Mental and Emotional Challenges:**\n",
      "\n",
      "    *   **Isolation and Boredom:** Four days of walking can be monotonous. This could lead to arguments among the party, morale issues, or a lack of vigilance.\n",
      "    *   **Psychological Effects:** The path may have a strange effect on the mind. Vivid dreams, hallucinations (especially at night), or a growing sense of dread could plague the characters. The dreams might show events in the future or past.\n",
      "\n",
      "**Things to Consider:**\n",
      "\n",
      "*   **Resting Point:** Where will the party make camp for the night? Is there a designated spot along the path, or do they have to choose their own? Is the area safe and defensible?\n",
      "*   **First Encounter:** Perhaps the party spots another group on the path. Are they pilgrims? Are they friendly? Do they seem to be up to no good? Perhaps some bandits are trying to prey on pilgrims, hoping to catch easy targets.\n",
      "\n",
      "**Areas of Uncertainty:**\n",
      "\n",
      "*   **The Specific Traditions:** The exact nature of the Pilgrim's Path traditions is crucial. The more detailed you make them, the more opportunities there are for roleplaying and potential consequences.\n",
      "*   **The Nature of the \"Distortions\":** We know the path is the only safe route because of \"strange distortions\" elsewhere. It might be too early to reveal the exact nature of these distortions on the first day, but subtle hints (strange mirages in the distance, unsettling sounds that seem to come from nowhere) could add to the atmosphere.\n",
      "*   **The Destination Monastery:** The nature of the ruined monastery will inform the dangers of the path leading to it. Are there lingering spirits, a powerful curse, or a dangerous presence that affects the path itself?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test with semantic search\n",
    "query = \"Describe the first day of walking the pilgrims path, what dangers avaits the adventurers?\"\n",
    "print(generate_response(system_prompt, query, vector_store_s_search.texts, vector_store_s_search.vectors).text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a breakdown of the first day on the Pilgrim's Path, focusing on what the adventurers might encounter:\n",
      "\n",
      "*   **Setting and Weather:**\n",
      "\n",
      "    *   The day begins with a \"crisp and cloudy\" atmosphere.\n",
      "    *   The path winds through dense forest for the first half of the day. This means potentially limited visibility and navigation challenges.\n",
      "    *   The afternoon brings the adventurers to the eastern shore of Mirror Lake, offering expansive views. Be sure to describe the beauty of the lake and the distant mountains to the players.\n",
      "    *   The text mentions that the party can see all the way to the opposite shore, but they are unable to travel too far out into the lake, or they will enter the Willowshore mindscape\n",
      "\n",
      "*   **Strange Path Effects:**\n",
      "\n",
      "    *   The path is strangely preserved, appearing as it did decades ago when the monastery was active. This can create an eerie or unsettling atmosphere.\n",
      "    *   The passage of time is distorted. No matter how fast or slow the party moves, it takes a full 8 hours to reach the Bridge Shrine. This can lead to frustration for players who want to rush or a sense of unease about the nature of the path.\n",
      "    *   Returning to Willowshore is always a quick, one-hour trip, skipping previously visited shrines. This reinforces the idea that the Pilgrim's Path is a unique and unnatural space.\n",
      "    *   A PC can attempt a DC 20 Occultism check to understand the path is a constrained version of the curse that contains Willowshore\n",
      "\n",
      "*   **Dangers and Encounters:**\n",
      "\n",
      "    *   **Difficult Terrain:** The forest surrounding the Pilgrim's Path is difficult terrain, slowing movement and potentially causing exhaustion.\n",
      "    *   **Tormented Kappa (Low 5):** The adventurers will encounter a Tormented Kappa soon after they begin their journey. The text does not specify how many Kappa, but I think it is fair to assume only one Kappa given the 'LOW 5' designation.\n",
      "    *   **Mirror Lake Hazards:** While scenic, Mirror Lake presents a potential hazard. Venturing too far into the lake leads to the edge of the Willowshore mindscape. This could mean disorientation, strange visions, or even being pulled into a different reality. (I am less certain about the exact consequences of this).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with fixed length\n",
    "query = \"Describe the first day of walking the pilgrims path, what dangers avaits the adventurers?\"\n",
    "print(generate_response(system_prompt, query, vector_store_fixed_length.texts, vector_store_fixed_length.vectors).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4fb9b",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e80de757",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = [\n",
    "    {\n",
    "        \"question\": \"What faction does Old Matsuki represent?\",\n",
    "        \"ideal_answer\": \"Southbank\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What NPC's help the PC's when researching the willowshore curse?\",\n",
    "        \"ideal_answer\": \"You So-Jin, Igawa Jubei, Great Willow, \"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What happens when the Eternal Lantern is lit?\",\n",
    "        \"ideal_answer\": \"The monsters and perils abate, citizens come out of hiding but remain frienghtened. Gray Butcher and Mo Douqiu realize that their grip on Willowshore has grown tenuous. Gray Butcher takes to patrolling downtown's streets.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "401a13be",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_system_prompt = \"\"\"You are an intelligent evaluationsystem with the purpose of evaluating the answer of an AI-assistent. If the answer if close to the ideal answer, score it 1.0 (as long as the other information remains relevant). If it's wrong or not good enough score it 0. If it's partly correct score it 0.5. Motivate the score you give it.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e4bdc072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What NPC's help the PC's when researching the willowshore curse?\n",
      "Okay, based on the provided text, here's a breakdown of the NPCs who can assist the PCs in researching the Willowshore curse, and how they can help:\n",
      "\n",
      "*   **You So-Jin (of Graveside Manners):**\n",
      "    *   **Expertise:** Willowshore's history and forgotten local knowledge.\n",
      "    *   **How she helps:** PCs spend the week talking with her, uncovering historical insights related to the curse.\n",
      "    *   **Research Checks:** DC 17 Willowshore Lore or DC 19 Diplomacy.\n",
      "    *   **Roleplaying:** Maximum RP 2 (opportunity for roleplaying interactions).\n",
      "*   **Igawa Jubei (of Mother's Coil):**\n",
      "    *   **Expertise:** Arcane knowledge, potentially possessing relevant books or insights within her collection.\n",
      "    *   **How she helps:** PCs investigate at Mother's Coil, working with Igawa Jubei, speaking with her, and/or sifting through her books.\n",
      "    *   **Research Checks:** DC 17 Library Lore or DC 19 Arcana.\n",
      "    *   **Roleplaying:** Maximum RP 2 (opportunity for roleplaying interactions).\n",
      "*   **Great Willow (Kodama):**\n",
      "    *   **Expertise:** Spiritual guardian of the Willow Tree; helped determine the extent of the curse previously.\n",
      "    *   **How it helps:** Implies it can offer insight. (The text doesn't fully detail how the Great Willow helps *specifically* with researching the *cause* or *solution* to the curse, but it is implied it is helpful.)\n",
      "    *   **Research Checks:** The text doesn't specify any checks related to the Great Willow; implying that the knowledge can only be gained through roleplay, or the GM can determine the checks.\n",
      "    *   **Roleplaying:** Not stated.\n",
      "\n",
      "Score: 1.0\n",
      "Explanation:\n",
      "The answer identifies the 3 NPC's that help the PC's when researching the willowshore curse, and also accurately describes how they help. The formatting is also good.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data[1][\"question\"]\n",
    "print(query)\n",
    "\n",
    "response_s_search = generate_response(system_prompt, query, vector_store_s_search.texts, vector_store_s_search.vectors)\n",
    "print(response_s_search.text)\n",
    "\n",
    "evaluation_prompt = f\"\"\"Question: {query}\n",
    "Response with semantic chunking: {response_s_search.text}\n",
    "Ideal answer: {validation_data[0][\"ideal_answer\"]}\"\"\"\n",
    "\n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt, vector_store_s_search.texts, vector_store_s_search.vectors)\n",
    "\n",
    "print(evaluation_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fceb094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What NPC's help the PC's when researching the willowshore curse?\n",
      "Okay, based on the provided text, here's a breakdown of the NPCs who can assist the PCs in researching the Willowshore curse:\n",
      "\n",
      "*   **You So-Jin (of Graveside Manners):**\n",
      "\n",
      "    *   **Expertise:** Willowshore's history and forgotten lore.\n",
      "    *   **How she helps:** By speaking with her, the PCs can uncover historical information about Willowshore relevant to the curse.\n",
      "    *   **Research Point (RP) Maximum:** 2\n",
      "    *   **Research Checks:** DC 17 Willowshore Lore or DC 19 Diplomacy.\n",
      "\n",
      "*   **Igawa Jubei (of Mother's Coil):**\n",
      "\n",
      "    *   **Expertise:** Books and knowledge at Mother's Coil.\n",
      "    *   **How she helps:** Allows access to her collection of books and provides insights through conversation.\n",
      "    *   **RP Maximum:** 2\n",
      "    *   **Research Checks:** DC 17 Library Lore or DC 19 Arcana.\n",
      "\n",
      "*   **Great Willow (kodama):**\n",
      "\n",
      "    *   **Expertise:** The extent/nature of the curse (having helped determine it previously).\n",
      "    *   The text doesn't provide direct research checks associated with the Great Willow in this section, but it is described as a resource the PC's can work with.\n",
      "\n",
      "*   **You Nadoya:**\n",
      "    *   The text only lists the name of this NPC without any relevant information regarding their skills or the help they can provide the PC's.\n",
      "\n",
      "The response is good and contains all the information needed from the document. However, it does not explicitly state that You Nadoya does not provide assistance in researching the curse. Therefore I will give it 0.75.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data[1][\"question\"]\n",
    "print(query)\n",
    "\n",
    "response_fixed_length = generate_response(system_prompt, query, vector_store_fixed_length.texts, vector_store_fixed_length.vectors)\n",
    "print(response_fixed_length.text)\n",
    "evaluation_prompt = f\"\"\"Question: {query}\n",
    "Response with fixed-length chunking: {response_fixed_length.text}\n",
    "Ideal answer: {validation_data[0][\"ideal_answer\"]}\"\"\"\n",
    "\n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt, vector_store_fixed_length.texts, vector_store_fixed_length.vectors)\n",
    "\n",
    "print(evaluation_response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
